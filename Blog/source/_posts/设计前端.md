---
title: ch9_设计前端
tags: [SLAM实践]
date: {{ date }}
comments: true
mathjax: true
categories: SLAM十四讲
---

{%cq%}

本次实践将前几章内容结合进来，实际书写一个视觉里程计程序，由于单目相机存在初始化问题以及尺度问题，因此本实践采用的是最简单的RGB-D相机，但是使用的也只是RGB-D数据集，而非真正的RGB-D相机。

{%endcq%}

<!-- more -->

# 一、搭建VO框架

## 1.1 确定程序基本框架

### 项目目录框架

在编写一个小规模的库时，我们通常会建立一些文件夹，把源代码、头文件、文档、测试数据、配置文件、日志等等分类存放，这样会显得很有条理。如果一个库内容很多，我们还会把代码分解各个独立的小模块，以便测试。

我们的工程目录如下：

- **bin：**用来存放可执行的二进制文件；

- **include/myslam：** 存放 slam 模块的头文件，主要是`.h`。这种做法的理由是，当你把包含目录设到 include 时，在引用自己的头文件时，需要写` include ”myslam/xxx.h”`，这样不容易和别的库混淆。

- **src：**存放源代码文件，主要是 cpp；

- **lib：** 存放编译好的库文件；
- **build：**存放执行编译操作生成的中间文件；

- **config：** 存放配置文件；

- **cmake_modules：** 第三方库的 cmake 文件，在使用 g2o 之类的库中会用到它

- **test：** 存放测试用的文件，也是 cpp
- **dataset：**存放我们使用的RGB-D数据集
- **tools：**这里是对数据集操作用的python文件

![image-20220330203310388](image-20220330203310388.png)

### 基本数据结构

**帧：**一个帧是相机采集到的图像单位。它主要包含一个图像（RGB-D 情形下是一对图像）。此外，还有特征点、位姿、内参等信息。在视觉 SLAM 中我们会谈论关键帧（Key-frame），通常的做法是把某些我们认为更重要的帧保存起来，并认为相机轨迹就可以用这些关键帧来描述。关键帧如何选择是一个很大的问题，而且基于工程经验，很少有理论上的指导。

**路标：**路标点即图像中的特征点。当相机运动之后，我们还能估计它们的 3D 位置。通常，会把路标点放在一个地图当中，并将新来的帧与地图中的路标点进行匹配，估计相机位姿。

## 1.2 基本类的实现

刚开始的阶段。我们一共写五个类：Frame 为帧，Camera 为相机模型，MapPoint 为特征点/路标点，Map
管理特征点，Config 提供配置参数。

![image-20220330200432411](image-20220330200432411.png)

每个类对应一个头文件，一个源文件，由于许多类会引用很多头文件，所以我们不妨直接写一个头文件专门存放头文件，让所有的头文件都引这个头文件。当然，这个头文件里的内容是不断填充的，现在就以直接给出的形式呈现。

**WL_SLAM_VO/include/myslam/common_include.h**

```cpp
#ifndef COMMON_INCLUDE_H
#define COMMON_INCLUDE_H

// for Eigen
#include <Eigen/Core>
#include <Eigen/Geometry>
using Eigen::Vector2d;
using Eigen::Vector3d;

// for Sophus
#include <sophus/se3.h>
#include <sophus/so3.h>
using Sophus::SE3;
using Sophus::SO3;


// for cv
#include <opencv2/core/core.hpp>
using cv::Mat;

// std 
#include <vector>
#include <list>
#include <memory>
#include <string>
#include <iostream>
#include <set>
#include <unordered_map>
#include <map>

using namespace std; 
#endif
```

### Camera类

Camera 类存储相机的内参和外参，并完成相机坐标系、像素坐标系、和世界坐标系之间的坐标变换。当然，在世界坐标系中你需要一个相机的（变动的）外参，我们以参数的形式传入。

**WL_SLAM_VO/include/myslam/Camera.h**

```cpp
#ifndef CAMERA
#define CAMERA
#include "myslam/common_include.h"

/* 我们用命名空间 namespace myslam 
将类定义包裹起来命名空间可以防止我们不小心定义出别的库里同名的函数，也是一种比较安全和规范的做法。*/ 
namespace mysalm
{

class Camera
{
public:
    // 把智能指针定义成 Camera 的指针类型，因此以后在传递参数时，只需用 Camera::Ptr 类型即可
    typedef std::shared_ptr<Camera> Ptr;
    // 相机内参
    float fx_, fy_, cx_, cy_, depth_scale_;

    Camera();

    Camera(float fx,float fy,float cx,float cy, float depth_scale) : 
        fx_(fx),fy_(fy),cx_(cx),cy_(cy),depth_scale_(depth_scale){}

    // 坐标变换
    Vector3d world2camera(const Vector3d &p_w, const SE3 &T_c_w);
    Vector3d camera2world(const Vector3d &p_c, const SE3 &T_c_w);
    Vector2d camera2pixel(const Vector3d &p_c);
    Vector2d pixel2camera(const Vector2d &p_p, double depth = 1);
    Vector3d pixel2world(const Vector2d &p_p, const SE3 &T_c_w, double depth = 1);
    Vector3d world2pixel(const Vector2d &p_w, const SE3 &T_c_w);
};      

}

#endif
```



>智能指针：std::shared_ptr
>
>`std::shared_ptr` 是一种智能指针，它能够记录多少个 `shared_ptr` 共同指向一个对象，从而消除显式的调用 `delete`，当引用计数变为零的时候就会将对象自动删除。
>
>`std::make_shared` 就能够用来消除显式的使用 `new`，所以`std::make_shared` 会分配创建传入参数中的对象， 并返回这个对象类型的`std::shared_ptr`指针。

**WL_SLAM_VO/src/camera.cpp**

```cpp
#include "myslam/camera.h"

namespace myslam
{
    Camera::Camera() {}

    Vector3d Camera::world2camera(const Vector3d &p_w, const SE3 &T_c_w)
    {
        return T_c_w * p_w;
    }
    Vector3d Camera::camera2world(const Vector3d &p_c, const SE3 &T_c_w)
    {
        return T_c_w.inverse() * p_c;
    }
    Vector2d Camera::camera2pixel(const Vector3d &p_c)
    {
        return Vector2d(
            fx_ * p_c(0, 0) / p_c(2, 0) + cx_,  // u = fx*X/Z+cx
            fx_ * p_c(1, 0) / p_c(2, 0) + cy_); // v = fy*Y/Z+cy
    }
    Vector3d Camera::pixel2camera(const Vector2d &p_p, double depth = 1)
    {
        return Vector3d(
            (p_p(0, 0) - cx_) * depth / fx_, // X = (u-cx)*Z/fx
            (p_p(1, 0) - cy_) * depth / fy_, // Y = (v-cy)*Z/fy
            depth);
    }

    Vector3d Camera::pixel2world(const Vector2d &p_p, const SE3 &T_c_w, double depth = 1)
    {
        return camera2world(pixel2camera(p_p, depth), T_c_w);
    }
    Vector2d Camera::world2pixel(const Vector3d &p_w, const SE3 &T_c_w)
    {
        return camera2pixel(world2camera(p_w, T_c_w));
    }

} // namespace myslam

```

### Frame类

由于 Frame 类是基本数据单元，在许多地方会用到它，但现在初期设计阶段，我们还不清楚以后可能新加的内容。所以这里的 Frame 类只提供基本的数据存储和接口。如果之后有新增的内容，我们就继续往里添加。

**WL_SLAM_VO/include/myslam/frame.h**

```cpp
#include "myslam/common_include.h"
#include "myslam/camera.h"
#ifndef FRAME
#define FRAME
namespace myslam
{
// 提前声明MapPoint类，需要用到帧的关键点
class MapPoint;
class Frame
{
public:
    typedef std::shared_ptr<Frame> Ptr; // 定义Frame类的智能指针
    unsigned long id_;                  // 图像帧的id编号
    double time_stamp_;                 // 图像帧被记录的时间戳
    SE3 T_c_w_;                         // 世界坐标系到相机坐标系的变换矩阵
    Camera::Ptr camera_;                //针孔RGB-D相机模型
    Mat color_, depth_;                 // 彩色图以及图像深度

public:
    Frame();
    Frame(long id, double time_stamp=0, SE3 T_c_w=SE3(), Camera::Ptr=nullptr,
        Mat color = Mat(),Mat depth = Mat() );
    ~Frame();
    
    // 创建帧
    static Frame::Ptr creatFrame();
    // 寻找给定点对应的深度 
    double findDepth(const cv::KeyPoint &kp);
    // 获取相机光心
    Vector3d getCamCenter() const;
    // 判断某个点是否在视野内
    bool isInFrame(const Vector3d &pt_world);

};
} // namespace myslam
#endif
```

**WL_SLAM_VO/src/frame.cpp**

```cpp
#include "myslam/common_include.h"
#include "myslam/frame.h"

namespace myslam
{
// 构造与析构
Frame::Frame() : id_(-1),time_stamp_(-1),camera_(nullptr){}
Frame::Frame ( long id, double time_stamp, SE3 T_c_w, Camera::Ptr camera, Mat color, Mat depth )
: id_(id), time_stamp_(time_stamp), T_c_w_(T_c_w), camera_(camera), color_(color), depth_(depth)
{

}
Frame::~Frame(){}

// 创建 Frame
Frame::Ptr Frame::creatFrame()
{
    static long factory_id = 0;
    return Frame::Ptr( new Frame(factory_id++) );
}
// 寻找给定点对应的深度
double Frame::findDepth(const cv::KeyPoint &kp)
{
    // 获得像素点的坐标
    int x = cvRound(kp.pt.x);
    int y = cvRound(kp.pt.y);
    // 得到像素点的深度
    ushort d = depth_.ptr<ushort>(y)[x];
    if(d != 0)
    {
        return double(d)/camera_->depth_scale_;
    }else
    {
        // 如果该像素深度为0，则选择附近的点作为参考
        int dx[4] = {-1,0,1,0};
        int dy[4] = {0,-1,0,1};
        for (int i = 0; i < 4; i++)
        {
            d = depth_.ptr<ushort>(y+dy[i])[x+dx[i]];
            if(d != 0)
            {
                return double(d)/camera_->depth_scale_;
            }
        }      
    }
    return -1.0;
}
// 获取相机光心
Vector3d Frame::getCamCenter() const
{
    //相机坐标系的（0,0,0）在世界坐标系下的位置
    return T_c_w_.inverse().translation();
}
// 判断某个点是否在视野内
bool Frame::isInFrame(const Vector3d &pt_world)
{
    // 将世界坐标系下的点转换为相机坐标系
    Vector3d p_cam = camera_->world2camera(pt_world,T_c_w_);
    if (p_cam(2.0)<0) // Z小于0
        return false;
    Vector2d pixel = camera_->world2pixel(pt_world,T_c_w_);
    return pixel(0,0)>0 
        && pixel(1,0)>0 
        && pixel(0,0)<color_.cols 
        && pixel(1,0)<color_.rows;
}
} // namespace myslam
```

### MapPoint 类

**WL_SLAM_VO/include/myslam/mappoint.h**

MapPoint 表示路标点。我们将估计它的世界坐标，并且我们会拿当前帧提取到的特征点与地图中的路标点匹配，来估计相机的运动，因此还需要存储它对应的描述子。此外，我们会记录一个点被观测到的次数和被匹配到的次数，作为评价它的好坏程度的指标。

```

```

### Map类

**WL_SLAM_VO/include/myslam/map.h**

Map 类管理着所有的路标点，并负责添加新路标、删除不好的路标等工作。VO 的匹配过程只需要和 Map 打交道即可。当然 Map 也会有很多操作，但现阶段我们只定义主要的数据结构。

**WL_SLAM_VO/src/map.h**
